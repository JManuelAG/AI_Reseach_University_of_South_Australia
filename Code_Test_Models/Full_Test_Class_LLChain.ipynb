{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "\n",
    "class LLMTemplateTester:\n",
    "    def __init__(self, repo_id):\n",
    "        os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
    "        # Ignore specific FutureWarnings\n",
    "        warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"huggingface_hub.utils._deprecation\")\n",
    "        self.repo_id = repo_id\n",
    "        self._model_kwargs = {\n",
    "            \"min_length\": 10,\n",
    "            \"max_length\": 60,\n",
    "            \"temperature\": 1,\n",
    "            \"top_p\": 0.3,\n",
    "            \"early_stopping\": True,\n",
    "            \"length_penalty\": 1,\n",
    "            \"num_beams\": 5,\n",
    "            \"no_repeat_ngram_size\": 2,\n",
    "            \"do_sample\": True,  # False for summarisation\n",
    "            \"repetition_penalty\": 1.2,\n",
    "            }\n",
    "        \n",
    "        self._tests = [\"question\", \"summarize\", \"qa\"]\n",
    "        self.current_state = \"question\"\n",
    "\n",
    "        # Read data \n",
    "        with open('../Datasets/Medical_Documents/test.dat', 'r') as file:\n",
    "            self.lines = file.readlines()\n",
    "\n",
    "    @property\n",
    "    def model_kwargs(self):\n",
    "        return self._model_kwargs\n",
    "\n",
    "    @model_kwargs.setter\n",
    "    def model_kwargs(self, new_kwargs):\n",
    "        for key, value in new_kwargs.items():\n",
    "            self._model_kwargs[key] = value\n",
    "        self._setup_hub()\n",
    "\n",
    "    # Function that changes the state based on the type of test is doing\n",
    "    def set_current_state(self, test):\n",
    "        self.current_state = test\n",
    "        self.set_template()\n",
    "        self.set_questions()\n",
    "        self.set_contexts()\n",
    "\n",
    "    # Chose the prompt template that will be used\n",
    "    def set_template(self):\n",
    "        templates = {\n",
    "            \"question\": \"Answer the question: {question}\",\n",
    "            \"summarize\": \"Summarize the text: {question}\",\n",
    "            \"qa\": \"From the following context text answer the question. If you don't know answer I don't know.\\nContext: {context}\\nQuestion: {question}\"\n",
    "            }\n",
    "        self.template = templates[self.current_state]\n",
    "\n",
    "    # Chose the question from the templates \n",
    "    def set_questions(self):\n",
    "        test_questions = {\n",
    "            \"qa\": [\n",
    "                \"What's my name?\",\n",
    "                \"How many patient files?\",\n",
    "                \"Give me the insights?\",\n",
    "                \"What is the problem?\"\n",
    "                ],\n",
    "            \"summarize\": [\n",
    "                self.lines[5099],  \n",
    "                self.lines[2197],  \n",
    "                self.lines[0]      \n",
    "                ],\n",
    "            \"question\": [\n",
    "                \"What are ICD-10 codes used for?\",\n",
    "                \"Who is Elton John?\",\n",
    "                \"Whatâ€™s clinical NLP?\",\n",
    "                \"What are the Symptoms of Malaria?\",\n",
    "                \"What is the ICD10 code of Malaria?\"\n",
    "                ]\n",
    "            }\n",
    "        self.questions = test_questions[self.current_state]\n",
    "\n",
    "    # Set the context for the type of text, some context are empty \n",
    "    def set_contexts(self):\n",
    "        test_context = {\n",
    "            \"qa\": [\n",
    "                \"My name is Clara and I live in Berkeley.\",\n",
    "                self.lines[0], self.lines[0], self.lines[0]],\n",
    "            \"summarize\": [\"\", \"\", \"\"],\n",
    "            \"question\": [\"\", \"\", \"\", \"\", \"\"]\n",
    "        }\n",
    "        self.contexts = test_context[self.current_state]\n",
    "    \n",
    "    def _setup_hub(self):\n",
    "        self.hub_llm = HuggingFaceHub(repo_id=self.repo_id, \n",
    "                                      model_kwargs=self._model_kwargs)\n",
    "    \n",
    "    def set_prompt(self):\n",
    "        # Set up promp template base on the type of test  [question, summarize, qa]                 \n",
    "        self.prompt = PromptTemplate(\n",
    "            input_variables=[\"question\", \"context\"],\n",
    "            template= self.template # template will vary base on the test [question, summarize, qa]\n",
    "            )\n",
    "        self.set_chain()\n",
    "    \n",
    "    def set_chain(self):\n",
    "        verbose = False\n",
    "        # Verbose changes for summarization \n",
    "        if self.current_state == \"summarize\":\n",
    "            verbouse = True\n",
    "        # Set up chain\n",
    "        self.hub_chain = LLMChain(prompt=self.prompt, \n",
    "                                  llm=self.hub_llm, \n",
    "                                  verbose=verbose # True for summarization\n",
    "                                  )\n",
    "    \n",
    "    # Start running the test based on the type of task or all of them\n",
    "    def run_test(self, test=\"all\"):\n",
    "        # All tests\n",
    "        if test == \"all\":\n",
    "            for test in self._tests:\n",
    "                self.run_test2(test)\n",
    "\n",
    "        # Test on a specific area \n",
    "        else:\n",
    "            self.run_test2(test)\n",
    "    \n",
    "    # Run the chain and save the answers\n",
    "    def run_test2(self, test):\n",
    "        if test == \"summarize\":\n",
    "            self.model_kwargs = {\"do_sample\": True}\n",
    "        else:\n",
    "            self.model_kwargs = {\"do_sample\": False}\n",
    "        \n",
    "        self.set_current_state(test)\n",
    "        self.set_prompt()\n",
    "\n",
    "        print(f\"\\n******* TEST FOR {self.current_state} **********\")\n",
    "        answers = []\n",
    "        for context, question in zip(self.contexts, self.questions):\n",
    "            answer = self.run_chain(context=context, question=question)\n",
    "            if test != \"summarize\":\n",
    "                print(\"\\nQustion: \", question)\n",
    "            print(\"Answer:\", answer)\n",
    "            answers.append(answer)\n",
    "        self.save_test(answers)\n",
    "    \n",
    "    # User interaction with the model for a one use only \n",
    "    def pipeline(self, test = \"question\", question = \" \", context = \" \"):\n",
    "        if test == \"summarize\":\n",
    "            self.model_kwargs = {\"do_sample\": True}\n",
    "        else:\n",
    "            self.model_kwargs = {\"do_sample\": False}\n",
    "        self.set_current_state(test)\n",
    "        self.set_prompt()\n",
    "        answer = self.run_chain(context=context, question=question)\n",
    "        if test != \"summarize\":\n",
    "                print(\"\\nQustion: \", question)\n",
    "        print(\"Answer:\", answer)\n",
    "\n",
    "    # Runs the chain and gives 2 different attemps waiting for the model to start up\n",
    "    def run_chain(self, context, question):\n",
    "        attempts = 2\n",
    "        while attempts > 0:\n",
    "            try:\n",
    "                answer = self.hub_chain.run(context=context, question=question)\n",
    "                return answer\n",
    "            except Exception as e:\n",
    "                attempts -= 1\n",
    "                if attempts == 0:\n",
    "                    print(\"Model didn't work\")\n",
    "                    return  \"Model didn't work\"\n",
    "                print(f\"An error occurred: {e}. Retrying in 20 seconds...\")\n",
    "                time.sleep(20)  # Wait for 20 seconds before retrying\n",
    "    \n",
    "    # Save the test on the result file\n",
    "    def save_test(self, answers):\n",
    "        file_path = \"../Test_Results/Test Results.xlsx\"\n",
    "        sheet_name = self.current_state\n",
    "        answers.insert(0, self.repo_id)\n",
    "        new_data = pd.DataFrame([answers])\n",
    "\n",
    "        # Try to read the existing data\n",
    "        try:\n",
    "            existing_data = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "        except FileNotFoundError:\n",
    "            existing_data = pd.DataFrame()\n",
    "\n",
    "        # Append new data\n",
    "        updated_data = pd.concat([existing_data, new_data], ignore_index=True)\n",
    "        updated_data = updated_data.drop_duplicates()\n",
    "\n",
    "        # Write back to Excel\n",
    "        with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "            updated_data.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One task sample usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Qustion:  Who is Maradona?\n",
      "Answer: \n",
      "AnswerAnswer Answer Answer\n",
      "QuestionQuestion The\n",
      "\n",
      "The The The Question QuestionTheThe\n",
      " QuestionWhoThe Who WhoWhoWho\n",
      "WhoWhat What What Who WhatWhatWhat\n"
     ]
    }
   ],
   "source": [
    "test = LLMTemplateTester(repo_id=\"RWKV/rwkv-raven-1b5\")\n",
    "test.pipeline(question=\"Who is Maradona?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a test on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******* TEST FOR question **********\n"
     ]
    }
   ],
   "source": [
    "test = LLMTemplateTester(repo_id=\"google/flan-t5-xl\")\n",
    "test.run_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run test on multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the .csv file with models\n",
    "df = pd.read_excel(\"../Test_Results/Initial Test.xlsx\")\n",
    "\n",
    "# Only test models for text generation (in this case tex2text is also consider text generation)\n",
    "for model in df[~df['Text Generation'].isna()].iloc[0:5,0]:\n",
    "    print(\"\\n\\n------------------------------------- TESTING MODEL:\", model)\n",
    "    test = LLMTemplateTester(repo_id=model)\n",
    "    test.run_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
