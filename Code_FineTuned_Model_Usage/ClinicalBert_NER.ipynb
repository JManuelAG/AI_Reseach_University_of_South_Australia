{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, AutoModel, pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Model: Bert  \n",
    "Task: NER  \n",
    "Description: The following model was trained on MIMIC clinical notes  \n",
    "This model is helpful to use in other tasks and lightweighted "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model Parametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Setup the enviroment \n",
    "model_name = \"emilyalsentzer/Bio_ClinicalBERT\"  # Example BioBERT model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'LABEL_0', 1: 'LABEL_1'}\n"
     ]
    }
   ],
   "source": [
    "# Understand the labels\n",
    "labels = model.config.id2label\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    }
   ],
   "source": [
    "# Creates pipeline\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data \n",
    "file_path = \"\"\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    # process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Recurrent buccal space abscesses: a complication of Crohn's disease. A patient is described with generalized gastrointestinal involvement by Crohn's disease. Symptoms of recurrent ulceration and mucosal tags are well-described oral manifestations of Crohn's disease; however, in our patient recurrent facial abscesses, which required extraoral drainage, also developed. This complication has not previously been reported. \\n\""
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process Text to Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = \"Patient complains of severe headache and chest pain. Located primarily in the frontal lobe and sternum.\"\n",
    "text = lines[6]\n",
    "\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NER Using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the text \n",
    "ner_results = ner_pipeline(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: the, Label: LABEL_0\n",
      "Entity: 29th, Label: LABEL_0\n",
      "Entity: r, Label: LABEL_0\n",
      "Entity: ##ove, Label: LABEL_0\n",
      "Entity: ##nst, Label: LABEL_0\n",
      "Entity: ##ine, Label: LABEL_0\n",
      "Entity: lecture, Label: LABEL_0\n",
      "Entity: :, Label: LABEL_0\n",
      "Entity: clinical, Label: LABEL_0\n",
      "Entity: challenges, Label: LABEL_0\n",
      "Entity: for, Label: LABEL_1\n",
      "Entity: the, Label: LABEL_0\n",
      "Entity: an, Label: LABEL_1\n",
      "Entity: ##est, Label: LABEL_0\n",
      "Entity: ##hes, Label: LABEL_0\n",
      "Entity: ##iol, Label: LABEL_0\n",
      "Entity: ##ogist, Label: LABEL_1\n",
      "Entity: ., Label: LABEL_0\n",
      "Entity: in, Label: LABEL_0\n",
      "Entity: conclusion, Label: LABEL_1\n",
      "Entity: ,, Label: LABEL_0\n",
      "Entity: i, Label: LABEL_0\n",
      "Entity: hope, Label: LABEL_0\n",
      "Entity: that, Label: LABEL_0\n",
      "Entity: my, Label: LABEL_0\n",
      "Entity: comments, Label: LABEL_0\n",
      "Entity: have, Label: LABEL_0\n",
      "Entity: re, Label: LABEL_0\n",
      "Entity: ##af, Label: LABEL_0\n",
      "Entity: ##firmed, Label: LABEL_0\n",
      "Entity: your, Label: LABEL_0\n",
      "Entity: bias, Label: LABEL_0\n",
      "Entity: ##es, Label: LABEL_0\n",
      "Entity: or, Label: LABEL_0\n",
      "Entity: ,, Label: LABEL_0\n",
      "Entity: even, Label: LABEL_0\n",
      "Entity: more, Label: LABEL_0\n",
      "Entity: importantly, Label: LABEL_0\n",
      "Entity: ,, Label: LABEL_0\n",
      "Entity: stimulate, Label: LABEL_0\n",
      "Entity: ##d, Label: LABEL_0\n",
      "Entity: you, Label: LABEL_0\n",
      "Entity: to, Label: LABEL_0\n",
      "Entity: think, Label: LABEL_0\n",
      "Entity: in, Label: LABEL_0\n",
      "Entity: a, Label: LABEL_1\n",
      "Entity: different, Label: LABEL_0\n",
      "Entity: way, Label: LABEL_1\n",
      "Entity: about, Label: LABEL_0\n",
      "Entity: the, Label: LABEL_0\n",
      "Entity: information, Label: LABEL_0\n",
      "Entity: explosion, Label: LABEL_0\n",
      "Entity: in, Label: LABEL_0\n",
      "Entity: our, Label: LABEL_1\n",
      "Entity: specialty, Label: LABEL_1\n",
      "Entity: and, Label: LABEL_0\n",
      "Entity: medicine, Label: LABEL_0\n",
      "Entity: in, Label: LABEL_1\n",
      "Entity: general, Label: LABEL_1\n",
      "Entity: ., Label: LABEL_0\n",
      "Entity: i, Label: LABEL_0\n",
      "Entity: believe, Label: LABEL_0\n",
      "Entity: our, Label: LABEL_1\n",
      "Entity: specialty, Label: LABEL_0\n",
      "Entity: is, Label: LABEL_0\n",
      "Entity: in, Label: LABEL_0\n",
      "Entity: a, Label: LABEL_1\n",
      "Entity: golden, Label: LABEL_0\n",
      "Entity: era, Label: LABEL_1\n",
      "Entity: that, Label: LABEL_0\n",
      "Entity: will, Label: LABEL_0\n",
      "Entity: benefit, Label: LABEL_0\n",
      "Entity: from, Label: LABEL_0\n",
      "Entity: the, Label: LABEL_0\n",
      "Entity: past, Label: LABEL_1\n",
      "Entity: and, Label: LABEL_0\n",
      "Entity: be, Label: LABEL_0\n",
      "Entity: no, Label: LABEL_0\n",
      "Entity: ##uri, Label: LABEL_1\n",
      "Entity: ##shed, Label: LABEL_0\n",
      "Entity: by, Label: LABEL_0\n",
      "Entity: new, Label: LABEL_0\n",
      "Entity: discoveries, Label: LABEL_0\n",
      "Entity: and, Label: LABEL_0\n",
      "Entity: understanding, Label: LABEL_0\n",
      "Entity: ., Label: LABEL_0\n",
      "Entity: we, Label: LABEL_0\n",
      "Entity: as, Label: LABEL_0\n",
      "Entity: clinic, Label: LABEL_0\n",
      "Entity: ##ians, Label: LABEL_0\n",
      "Entity: must, Label: LABEL_0\n",
      "Entity: accept, Label: LABEL_0\n",
      "Entity: the, Label: LABEL_1\n",
      "Entity: challenge, Label: LABEL_0\n",
      "Entity: of, Label: LABEL_1\n",
      "Entity: recognizing, Label: LABEL_0\n",
      "Entity: what, Label: LABEL_0\n",
      "Entity: new, Label: LABEL_0\n",
      "Entity: information, Label: LABEL_1\n",
      "Entity: deserves, Label: LABEL_0\n",
      "Entity: incorporation, Label: LABEL_0\n",
      "Entity: into, Label: LABEL_0\n",
      "Entity: our, Label: LABEL_1\n",
      "Entity: practice, Label: LABEL_1\n",
      "Entity: ,, Label: LABEL_0\n",
      "Entity: what, Label: LABEL_0\n",
      "Entity: old, Label: LABEL_0\n",
      "Entity: information, Label: LABEL_0\n",
      "Entity: deserves, Label: LABEL_0\n",
      "Entity: to, Label: LABEL_1\n",
      "Entity: be, Label: LABEL_0\n",
      "Entity: sustained, Label: LABEL_0\n",
      "Entity: ,, Label: LABEL_0\n",
      "Entity: and, Label: LABEL_0\n",
      "Entity: what, Label: LABEL_0\n",
      "Entity: merits, Label: LABEL_0\n",
      "Entity: new, Label: LABEL_0\n",
      "Entity: scrutiny, Label: LABEL_0\n",
      "Entity: and, Label: LABEL_0\n",
      "Entity: perhaps, Label: LABEL_1\n",
      "Entity: should, Label: LABEL_0\n",
      "Entity: be, Label: LABEL_1\n",
      "Entity: discarded, Label: LABEL_0\n",
      "Entity: ., Label: LABEL_0\n",
      "Entity: if, Label: LABEL_0\n",
      "Entity: i, Label: LABEL_0\n",
      "Entity: had, Label: LABEL_0\n",
      "Entity: one, Label: LABEL_0\n",
      "Entity: wish, Label: LABEL_0\n",
      "Entity: ,, Label: LABEL_0\n",
      "Entity: it, Label: LABEL_0\n",
      "Entity: would, Label: LABEL_0\n",
      "Entity: be, Label: LABEL_0\n",
      "Entity: that, Label: LABEL_0\n",
      "Entity: an, Label: LABEL_0\n",
      "Entity: ##est, Label: LABEL_0\n",
      "Entity: ##hes, Label: LABEL_0\n",
      "Entity: ##iol, Label: LABEL_0\n",
      "Entity: ##ogist, Label: LABEL_1\n",
      "Entity: ##s, Label: LABEL_0\n",
      "Entity: would, Label: LABEL_0\n",
      "Entity: never, Label: LABEL_0\n",
      "Entity: lose, Label: LABEL_0\n",
      "Entity: their, Label: LABEL_0\n",
      "Entity: z, Label: LABEL_0\n",
      "Entity: ##eal, Label: LABEL_0\n",
      "Entity: to, Label: LABEL_0\n",
      "Entity: be, Label: LABEL_0\n",
      "Entity: students, Label: LABEL_0\n",
      "Entity: -, Label: LABEL_1\n",
      "Entity: -, Label: LABEL_0\n",
      "Entity: their, Label: LABEL_0\n",
      "Entity: thirst, Label: LABEL_0\n",
      "Entity: for, Label: LABEL_0\n",
      "Entity: new, Label: LABEL_0\n",
      "Entity: information, Label: LABEL_1\n",
      "Entity: -, Label: LABEL_1\n",
      "Entity: -, Label: LABEL_1\n",
      "Entity: as, Label: LABEL_0\n",
      "Entity: the, Label: LABEL_0\n",
      "Entity: con, Label: LABEL_0\n",
      "Entity: ##tinuum, Label: LABEL_0\n",
      "Entity: of, Label: LABEL_0\n",
      "Entity: an, Label: LABEL_0\n",
      "Entity: ##est, Label: LABEL_0\n",
      "Entity: ##hesia, Label: LABEL_0\n",
      "Entity: education, Label: LABEL_0\n",
      "Entity: is, Label: LABEL_0\n",
      "Entity: indeed, Label: LABEL_0\n",
      "Entity: a, Label: LABEL_1\n",
      "Entity: life, Label: LABEL_0\n",
      "Entity: -, Label: LABEL_1\n",
      "Entity: long, Label: LABEL_1\n",
      "Entity: process, Label: LABEL_0\n",
      "Entity: ., Label: LABEL_0\n",
      "Entity: that, Label: LABEL_0\n",
      "Entity: wish, Label: LABEL_0\n",
      "Entity: ,, Label: LABEL_0\n",
      "Entity: ladies, Label: LABEL_0\n",
      "Entity: and, Label: LABEL_0\n",
      "Entity: gentlemen, Label: LABEL_0\n",
      "Entity: ,, Label: LABEL_0\n",
      "Entity: is, Label: LABEL_1\n",
      "Entity: my, Label: LABEL_1\n",
      "Entity: challenge, Label: LABEL_0\n",
      "Entity: to, Label: LABEL_0\n",
      "Entity: all, Label: LABEL_0\n",
      "Entity: an, Label: LABEL_1\n",
      "Entity: ##est, Label: LABEL_0\n",
      "Entity: ##hes, Label: LABEL_0\n",
      "Entity: ##iol, Label: LABEL_1\n",
      "Entity: ##ogist, Label: LABEL_1\n",
      "Entity: ##s, Label: LABEL_0\n",
      "Entity: ., Label: LABEL_1\n"
     ]
    }
   ],
   "source": [
    "# show results \n",
    "for entity in ner_results:\n",
    "    print(f\"Entity: {entity['word']}, Label: {entity['entity']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
